{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MP_DATA') \n",
    "\n",
    "# Actions that we try to detect\n",
    "#actions = np.array(['hello','iloveyou','thanks','google','house','jogging','book','internet'])\n",
    "actions = np.array(['drink','house','drive','hello','iloveyou','thanks','google','internet','jogging','book'])\n",
    "#actions = np.array(['hello','iloveyou','thanks','google','internet','pizza','jogging','book'])\n",
    "#actions = np.array(['hello','book','computer','drink','iloveyou','thanks','before', 'chair', 'go']) ,'before', 'chair', 'go','clothes',''google','internet','pizza','televison','twitter',\n",
    " #'clothes','who', 'candy', 'cousin'\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 40\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions: \n",
    "    for sequence in range(no_sequences):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    # NEW LOOP\n",
    "    # Loop through actions\n",
    "    for action in actions:\n",
    "        # Loop through sequences aka videos\n",
    "        for sequence in range(no_sequences):\n",
    "            # Loop through video length aka sequence length\n",
    "            for frame_num in range(sequence_length):\n",
    "\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "#                 print(results)\n",
    "\n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "                \n",
    "                # NEW Apply wait logic\n",
    "                if frame_num == 0: \n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (90,90), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(2000)\n",
    "                else: \n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (90,90), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "                # NEW Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drink': 0,\n",
       " 'house': 1,\n",
       " 'drive': 2,\n",
       " 'hello': 3,\n",
       " 'iloveyou': 4,\n",
       " 'thanks': 5,\n",
       " 'google': 6,\n",
       " 'internet': 7,\n",
       " 'jogging': 8,\n",
       " 'book': 9}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 30, 1662)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 30, 1662)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu', input_shape=(30, 1662)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=False, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596906 (2.28 MB)\n",
      "Trainable params: 596906 (2.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [.7, 0.2, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drink'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "8/8 [==============================] - 5s 142ms/step - loss: 2.6245 - categorical_accuracy: 0.1172 - val_loss: 2.2837 - val_categorical_accuracy: 0.2031\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 2.2892 - categorical_accuracy: 0.1797 - val_loss: 2.2351 - val_categorical_accuracy: 0.2812\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 2.2018 - categorical_accuracy: 0.2227 - val_loss: 1.9080 - val_categorical_accuracy: 0.3906\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 2.1296 - categorical_accuracy: 0.3008 - val_loss: 2.0694 - val_categorical_accuracy: 0.2656\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.9518 - categorical_accuracy: 0.3516 - val_loss: 2.0004 - val_categorical_accuracy: 0.2812\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 1.7354 - categorical_accuracy: 0.3125 - val_loss: 1.6739 - val_categorical_accuracy: 0.3281\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 2.5375 - categorical_accuracy: 0.2500 - val_loss: 1.9762 - val_categorical_accuracy: 0.1250\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 2.0332 - categorical_accuracy: 0.3555 - val_loss: 1.9756 - val_categorical_accuracy: 0.2500\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.8250 - categorical_accuracy: 0.3633 - val_loss: 1.9311 - val_categorical_accuracy: 0.2500\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 1.8545 - categorical_accuracy: 0.3594 - val_loss: 1.9043 - val_categorical_accuracy: 0.3906\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 2.3529 - categorical_accuracy: 0.3555 - val_loss: 1.9379 - val_categorical_accuracy: 0.3281\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.9575 - categorical_accuracy: 0.3555 - val_loss: 1.6716 - val_categorical_accuracy: 0.3438\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 1.5763 - categorical_accuracy: 0.3516 - val_loss: 1.6156 - val_categorical_accuracy: 0.3906\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 1.4502 - categorical_accuracy: 0.4375 - val_loss: 1.5514 - val_categorical_accuracy: 0.3906\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 1s 136ms/step - loss: 1.4203 - categorical_accuracy: 0.4297 - val_loss: 1.5023 - val_categorical_accuracy: 0.4219\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 1.3691 - categorical_accuracy: 0.4648 - val_loss: 1.3800 - val_categorical_accuracy: 0.3906\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 1.2828 - categorical_accuracy: 0.4297 - val_loss: 1.5053 - val_categorical_accuracy: 0.3438\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 1.1991 - categorical_accuracy: 0.4922 - val_loss: 1.1584 - val_categorical_accuracy: 0.5156\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 1.0547 - categorical_accuracy: 0.5469 - val_loss: 1.0199 - val_categorical_accuracy: 0.5781\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.9809 - categorical_accuracy: 0.5898 - val_loss: 1.1124 - val_categorical_accuracy: 0.4062\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.9717 - categorical_accuracy: 0.5703 - val_loss: 1.0541 - val_categorical_accuracy: 0.4844\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.9107 - categorical_accuracy: 0.5781 - val_loss: 0.8180 - val_categorical_accuracy: 0.7188\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.7667 - categorical_accuracy: 0.6680 - val_loss: 0.7187 - val_categorical_accuracy: 0.6406\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.9242 - categorical_accuracy: 0.5781 - val_loss: 1.1572 - val_categorical_accuracy: 0.4531\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 1.3070 - categorical_accuracy: 0.5000 - val_loss: 1.3350 - val_categorical_accuracy: 0.3438\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.0884 - categorical_accuracy: 0.5000 - val_loss: 1.0380 - val_categorical_accuracy: 0.5000\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.9382 - categorical_accuracy: 0.5703 - val_loss: 0.9140 - val_categorical_accuracy: 0.5469\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.9013 - categorical_accuracy: 0.6211 - val_loss: 0.9359 - val_categorical_accuracy: 0.4844\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.7887 - categorical_accuracy: 0.6406 - val_loss: 0.7558 - val_categorical_accuracy: 0.5781\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.3600 - categorical_accuracy: 0.4297 - val_loss: 1.4294 - val_categorical_accuracy: 0.4062\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.3488 - categorical_accuracy: 0.4727 - val_loss: 1.3609 - val_categorical_accuracy: 0.5000\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.1878 - categorical_accuracy: 0.5273 - val_loss: 1.1749 - val_categorical_accuracy: 0.4531\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.0375 - categorical_accuracy: 0.5547 - val_loss: 1.0105 - val_categorical_accuracy: 0.5312\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.9767 - categorical_accuracy: 0.6016 - val_loss: 1.1294 - val_categorical_accuracy: 0.6406\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.1678 - categorical_accuracy: 0.4609 - val_loss: 1.5609 - val_categorical_accuracy: 0.3125\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.3585 - categorical_accuracy: 0.4180 - val_loss: 1.3807 - val_categorical_accuracy: 0.3281\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.2395 - categorical_accuracy: 0.4883 - val_loss: 1.2446 - val_categorical_accuracy: 0.4219\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.1431 - categorical_accuracy: 0.5117 - val_loss: 1.0470 - val_categorical_accuracy: 0.5156\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.0289 - categorical_accuracy: 0.5742 - val_loss: 0.9795 - val_categorical_accuracy: 0.4688\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.8221 - categorical_accuracy: 0.6875 - val_loss: 0.6339 - val_categorical_accuracy: 0.7656\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 1.3705 - categorical_accuracy: 0.4922 - val_loss: 1.4506 - val_categorical_accuracy: 0.4062\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.1447 - categorical_accuracy: 0.5273 - val_loss: 1.3798 - val_categorical_accuracy: 0.4062\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.9942 - categorical_accuracy: 0.5820 - val_loss: 1.0498 - val_categorical_accuracy: 0.5000\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.9556 - categorical_accuracy: 0.6172 - val_loss: 1.4073 - val_categorical_accuracy: 0.4688\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 1.4247 - categorical_accuracy: 0.4844 - val_loss: 1.2055 - val_categorical_accuracy: 0.6250\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.5280 - categorical_accuracy: 0.3750 - val_loss: 1.6105 - val_categorical_accuracy: 0.3281\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.3709 - categorical_accuracy: 0.4062 - val_loss: 1.2646 - val_categorical_accuracy: 0.4062\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 1.2643 - categorical_accuracy: 0.4688 - val_loss: 1.2641 - val_categorical_accuracy: 0.4688\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 2.9348 - categorical_accuracy: 0.4844 - val_loss: 2.8742 - val_categorical_accuracy: 0.2812\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.8183 - categorical_accuracy: 0.3867 - val_loss: 1.6916 - val_categorical_accuracy: 0.5312\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.5285 - categorical_accuracy: 0.4570 - val_loss: 1.4250 - val_categorical_accuracy: 0.5625\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 1.3180 - categorical_accuracy: 0.5234 - val_loss: 1.3207 - val_categorical_accuracy: 0.4688\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 1.2467 - categorical_accuracy: 0.4805 - val_loss: 1.1867 - val_categorical_accuracy: 0.5781\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.1557 - categorical_accuracy: 0.5195 - val_loss: 1.1426 - val_categorical_accuracy: 0.5625\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 1.0190 - categorical_accuracy: 0.5742 - val_loss: 0.9435 - val_categorical_accuracy: 0.5000\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.8615 - categorical_accuracy: 0.6250 - val_loss: 0.8939 - val_categorical_accuracy: 0.6406\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.8629 - categorical_accuracy: 0.6289 - val_loss: 0.8375 - val_categorical_accuracy: 0.6562\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.8842 - categorical_accuracy: 0.6016 - val_loss: 1.2624 - val_categorical_accuracy: 0.4375\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 1.0292 - categorical_accuracy: 0.5273 - val_loss: 0.8720 - val_categorical_accuracy: 0.7031\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.9147 - categorical_accuracy: 0.5703 - val_loss: 0.8183 - val_categorical_accuracy: 0.7031\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.8147 - categorical_accuracy: 0.6328 - val_loss: 0.7453 - val_categorical_accuracy: 0.6562\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.6906 - categorical_accuracy: 0.7031 - val_loss: 0.6960 - val_categorical_accuracy: 0.6406\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.6014 - categorical_accuracy: 0.7617 - val_loss: 0.6793 - val_categorical_accuracy: 0.7031\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.8501 - categorical_accuracy: 0.6445 - val_loss: 0.6855 - val_categorical_accuracy: 0.7031\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.6870 - categorical_accuracy: 0.6992 - val_loss: 0.5878 - val_categorical_accuracy: 0.7500\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.6147 - categorical_accuracy: 0.7305 - val_loss: 0.5211 - val_categorical_accuracy: 0.8594\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.6238 - categorical_accuracy: 0.7500 - val_loss: 0.4969 - val_categorical_accuracy: 0.6875\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.5950 - categorical_accuracy: 0.7422 - val_loss: 0.7332 - val_categorical_accuracy: 0.6406\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.7114 - categorical_accuracy: 0.6484 - val_loss: 1.0838 - val_categorical_accuracy: 0.4688\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.7765 - categorical_accuracy: 0.6328 - val_loss: 1.1535 - val_categorical_accuracy: 0.6719\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.7546 - categorical_accuracy: 0.6641 - val_loss: 0.7238 - val_categorical_accuracy: 0.6094\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.6450 - categorical_accuracy: 0.6992 - val_loss: 0.6681 - val_categorical_accuracy: 0.6406\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.5581 - categorical_accuracy: 0.7344 - val_loss: 0.5847 - val_categorical_accuracy: 0.7656\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.5552 - categorical_accuracy: 0.7773 - val_loss: 0.5398 - val_categorical_accuracy: 0.7656\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.5944 - categorical_accuracy: 0.6914 - val_loss: 0.4474 - val_categorical_accuracy: 0.7969\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.4068 - categorical_accuracy: 0.8164 - val_loss: 0.4464 - val_categorical_accuracy: 0.8594\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.4136 - categorical_accuracy: 0.8359 - val_loss: 0.3361 - val_categorical_accuracy: 0.9219\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.7483 - categorical_accuracy: 0.7539 - val_loss: 0.7594 - val_categorical_accuracy: 0.7031\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.7954 - categorical_accuracy: 0.6484 - val_loss: 0.9999 - val_categorical_accuracy: 0.5156\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.7711 - categorical_accuracy: 0.6133 - val_loss: 0.7059 - val_categorical_accuracy: 0.6719\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.7677 - categorical_accuracy: 0.6484 - val_loss: 0.6927 - val_categorical_accuracy: 0.6562\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.7317 - categorical_accuracy: 0.6797 - val_loss: 0.6825 - val_categorical_accuracy: 0.6719\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.6686 - categorical_accuracy: 0.6953 - val_loss: 0.6371 - val_categorical_accuracy: 0.6562\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.5496 - categorical_accuracy: 0.7383 - val_loss: 0.5431 - val_categorical_accuracy: 0.7656\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.5045 - categorical_accuracy: 0.7773 - val_loss: 0.5471 - val_categorical_accuracy: 0.6719\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.4145 - categorical_accuracy: 0.8711 - val_loss: 0.3461 - val_categorical_accuracy: 0.9062\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.4483 - categorical_accuracy: 0.8203 - val_loss: 0.3853 - val_categorical_accuracy: 0.7812\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.3547 - categorical_accuracy: 0.7930 - val_loss: 0.3741 - val_categorical_accuracy: 0.8125\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.3228 - categorical_accuracy: 0.8711 - val_loss: 0.2949 - val_categorical_accuracy: 0.9219\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.4348 - categorical_accuracy: 0.8398 - val_loss: 0.3092 - val_categorical_accuracy: 0.8906\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.3866 - categorical_accuracy: 0.8789 - val_loss: 0.4202 - val_categorical_accuracy: 0.7969\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.4489 - categorical_accuracy: 0.8086 - val_loss: 0.5573 - val_categorical_accuracy: 0.8281\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.6056 - categorical_accuracy: 0.7617 - val_loss: 0.6054 - val_categorical_accuracy: 0.7031\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.4678 - categorical_accuracy: 0.7695 - val_loss: 0.6521 - val_categorical_accuracy: 0.6562\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.3663 - categorical_accuracy: 0.8164 - val_loss: 0.4525 - val_categorical_accuracy: 0.7812\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.2504 - categorical_accuracy: 0.9219 - val_loss: 0.2393 - val_categorical_accuracy: 0.9219\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.1600 - categorical_accuracy: 0.9688 - val_loss: 0.1479 - val_categorical_accuracy: 0.9844\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.1604 - categorical_accuracy: 0.9453 - val_loss: 0.2251 - val_categorical_accuracy: 0.9375\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2344 - categorical_accuracy: 0.9141 - val_loss: 0.3185 - val_categorical_accuracy: 0.9219\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.3323 - categorical_accuracy: 0.8711 - val_loss: 0.2261 - val_categorical_accuracy: 0.9688\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.4107 - categorical_accuracy: 0.8477 - val_loss: 0.4775 - val_categorical_accuracy: 0.8750\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2622 - categorical_accuracy: 0.9219 - val_loss: 0.3229 - val_categorical_accuracy: 0.9375\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2627 - categorical_accuracy: 0.9062 - val_loss: 0.2344 - val_categorical_accuracy: 0.9688\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.3691 - categorical_accuracy: 0.8594 - val_loss: 0.4021 - val_categorical_accuracy: 0.7969\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 1.1999 - categorical_accuracy: 0.6797 - val_loss: 2.4245 - val_categorical_accuracy: 0.4844\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 1.7745 - categorical_accuracy: 0.4844 - val_loss: 1.3991 - val_categorical_accuracy: 0.4844\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.0783 - categorical_accuracy: 0.5312 - val_loss: 1.2234 - val_categorical_accuracy: 0.5625\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 1.0268 - categorical_accuracy: 0.6523 - val_loss: 0.9648 - val_categorical_accuracy: 0.7188\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.8386 - categorical_accuracy: 0.6133 - val_loss: 0.9039 - val_categorical_accuracy: 0.6406\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.7594 - categorical_accuracy: 0.7344 - val_loss: 0.7690 - val_categorical_accuracy: 0.7188\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.6482 - categorical_accuracy: 0.6680 - val_loss: 0.6589 - val_categorical_accuracy: 0.7344\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.5092 - categorical_accuracy: 0.8594 - val_loss: 0.4999 - val_categorical_accuracy: 0.8750\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.3710 - categorical_accuracy: 0.9102 - val_loss: 0.4164 - val_categorical_accuracy: 0.9375\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2762 - categorical_accuracy: 0.9570 - val_loss: 0.3161 - val_categorical_accuracy: 0.9375\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2222 - categorical_accuracy: 0.9570 - val_loss: 0.3039 - val_categorical_accuracy: 0.9531\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.2392 - categorical_accuracy: 0.9219 - val_loss: 0.2687 - val_categorical_accuracy: 0.9688\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2441 - categorical_accuracy: 0.9102 - val_loss: 0.4732 - val_categorical_accuracy: 0.8281\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2395 - categorical_accuracy: 0.9219 - val_loss: 0.2629 - val_categorical_accuracy: 0.9375\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2828 - categorical_accuracy: 0.8828 - val_loss: 0.6960 - val_categorical_accuracy: 0.7500\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2567 - categorical_accuracy: 0.8945 - val_loss: 0.3736 - val_categorical_accuracy: 0.9062\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2115 - categorical_accuracy: 0.9453 - val_loss: 0.2094 - val_categorical_accuracy: 0.9688\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.1732 - categorical_accuracy: 0.9492 - val_loss: 0.5420 - val_categorical_accuracy: 0.8281\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.3243 - categorical_accuracy: 0.9180 - val_loss: 0.5655 - val_categorical_accuracy: 0.7344\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 1.1177 - categorical_accuracy: 0.6445 - val_loss: 0.7964 - val_categorical_accuracy: 0.6719\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.4760 - categorical_accuracy: 0.8203 - val_loss: 0.6579 - val_categorical_accuracy: 0.8438\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.4409 - categorical_accuracy: 0.8906 - val_loss: 0.4651 - val_categorical_accuracy: 0.9375\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.3265 - categorical_accuracy: 0.9180 - val_loss: 0.4093 - val_categorical_accuracy: 0.9375\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2356 - categorical_accuracy: 0.9453 - val_loss: 0.4235 - val_categorical_accuracy: 0.8281\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.1682 - categorical_accuracy: 0.9570 - val_loss: 0.2687 - val_categorical_accuracy: 0.9531\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.1442 - categorical_accuracy: 0.9844 - val_loss: 0.2663 - val_categorical_accuracy: 0.9531\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.1056 - categorical_accuracy: 0.9922 - val_loss: 0.2552 - val_categorical_accuracy: 0.9375\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0973 - categorical_accuracy: 0.9844 - val_loss: 0.2382 - val_categorical_accuracy: 0.9531\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0818 - categorical_accuracy: 0.9844 - val_loss: 0.2383 - val_categorical_accuracy: 0.9531\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0548 - categorical_accuracy: 0.9922 - val_loss: 0.2276 - val_categorical_accuracy: 0.9531\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.0507 - categorical_accuracy: 0.9883 - val_loss: 0.2107 - val_categorical_accuracy: 0.9688\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0448 - categorical_accuracy: 0.9961 - val_loss: 0.2206 - val_categorical_accuracy: 0.9688\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.0284 - categorical_accuracy: 1.0000 - val_loss: 0.2240 - val_categorical_accuracy: 0.9688\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0238 - categorical_accuracy: 0.9961 - val_loss: 0.2732 - val_categorical_accuracy: 0.9531\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0189 - categorical_accuracy: 0.9961 - val_loss: 0.2578 - val_categorical_accuracy: 0.9531\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0360 - categorical_accuracy: 0.9883 - val_loss: 0.2449 - val_categorical_accuracy: 0.9531\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0607 - categorical_accuracy: 0.9844 - val_loss: 0.2525 - val_categorical_accuracy: 0.9219\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0772 - categorical_accuracy: 0.9727 - val_loss: 0.2315 - val_categorical_accuracy: 0.9219\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2297 - categorical_accuracy: 0.9297 - val_loss: 0.3862 - val_categorical_accuracy: 0.8750\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0986 - categorical_accuracy: 0.9570 - val_loss: 0.2189 - val_categorical_accuracy: 0.9375\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1390 - categorical_accuracy: 0.9492 - val_loss: 0.6637 - val_categorical_accuracy: 0.8125\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.7653 - categorical_accuracy: 0.8008 - val_loss: 0.8106 - val_categorical_accuracy: 0.6406\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.7106 - categorical_accuracy: 0.7734 - val_loss: 0.8577 - val_categorical_accuracy: 0.7344\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.4608 - categorical_accuracy: 0.8086 - val_loss: 0.3042 - val_categorical_accuracy: 0.9375\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.4671 - categorical_accuracy: 0.8320 - val_loss: 0.4121 - val_categorical_accuracy: 0.8281\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2797 - categorical_accuracy: 0.9023 - val_loss: 0.2593 - val_categorical_accuracy: 0.9531\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.1428 - categorical_accuracy: 0.9805 - val_loss: 0.2715 - val_categorical_accuracy: 0.9531\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.1329 - categorical_accuracy: 0.9805 - val_loss: 0.1952 - val_categorical_accuracy: 0.9688\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0792 - categorical_accuracy: 1.0000 - val_loss: 0.1920 - val_categorical_accuracy: 0.9844\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0603 - categorical_accuracy: 0.9961 - val_loss: 0.1855 - val_categorical_accuracy: 0.9688\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0682 - categorical_accuracy: 0.9883 - val_loss: 0.1947 - val_categorical_accuracy: 0.9688\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.0794 - categorical_accuracy: 0.9727 - val_loss: 0.1858 - val_categorical_accuracy: 0.9688\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0818 - categorical_accuracy: 0.9727 - val_loss: 0.1925 - val_categorical_accuracy: 0.9688\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0578 - categorical_accuracy: 0.9922 - val_loss: 0.2161 - val_categorical_accuracy: 0.9531\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0306 - categorical_accuracy: 0.9922 - val_loss: 0.2349 - val_categorical_accuracy: 0.9375\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0195 - categorical_accuracy: 0.9961 - val_loss: 0.2292 - val_categorical_accuracy: 0.9531\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.0236 - categorical_accuracy: 0.9922 - val_loss: 0.1920 - val_categorical_accuracy: 0.9688\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0895 - categorical_accuracy: 0.9727 - val_loss: 0.1930 - val_categorical_accuracy: 0.9688\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0631 - categorical_accuracy: 0.9844 - val_loss: 0.2451 - val_categorical_accuracy: 0.9219\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0784 - categorical_accuracy: 0.9805 - val_loss: 0.4518 - val_categorical_accuracy: 0.8594\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.0762 - categorical_accuracy: 0.9688 - val_loss: 0.3442 - val_categorical_accuracy: 0.9062\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0894 - categorical_accuracy: 0.9688 - val_loss: 0.2161 - val_categorical_accuracy: 0.9375\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.1565 - categorical_accuracy: 0.9570 - val_loss: 0.4801 - val_categorical_accuracy: 0.8438\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.0365 - categorical_accuracy: 0.9922 - val_loss: 0.3239 - val_categorical_accuracy: 0.9375\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0289 - categorical_accuracy: 1.0000 - val_loss: 0.2434 - val_categorical_accuracy: 0.9531\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.0292 - categorical_accuracy: 0.9922 - val_loss: 0.2392 - val_categorical_accuracy: 0.9375\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0186 - categorical_accuracy: 1.0000 - val_loss: 0.2049 - val_categorical_accuracy: 0.9531\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0152 - categorical_accuracy: 1.0000 - val_loss: 0.1532 - val_categorical_accuracy: 0.9844\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0087 - categorical_accuracy: 1.0000 - val_loss: 0.2237 - val_categorical_accuracy: 0.9531\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0056 - categorical_accuracy: 1.0000 - val_loss: 0.1701 - val_categorical_accuracy: 0.9844\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.0059 - categorical_accuracy: 1.0000 - val_loss: 0.2408 - val_categorical_accuracy: 0.9375\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0089 - categorical_accuracy: 1.0000 - val_loss: 0.2104 - val_categorical_accuracy: 0.9531\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.0065 - categorical_accuracy: 1.0000 - val_loss: 0.1815 - val_categorical_accuracy: 0.9844\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0128 - categorical_accuracy: 1.0000 - val_loss: 0.2188 - val_categorical_accuracy: 0.9531\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.0227 - categorical_accuracy: 0.9922 - val_loss: 0.3762 - val_categorical_accuracy: 0.9062\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.0659 - categorical_accuracy: 0.9688 - val_loss: 0.1738 - val_categorical_accuracy: 0.9688\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0867 - categorical_accuracy: 0.9648 - val_loss: 0.2209 - val_categorical_accuracy: 0.9688\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.1088 - categorical_accuracy: 0.9570 - val_loss: 0.2801 - val_categorical_accuracy: 0.9219\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2842 - categorical_accuracy: 0.8867 - val_loss: 0.6476 - val_categorical_accuracy: 0.7969\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.3411 - categorical_accuracy: 0.8906 - val_loss: 0.1713 - val_categorical_accuracy: 0.9688\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.3166 - categorical_accuracy: 0.8828 - val_loss: 1.0442 - val_categorical_accuracy: 0.6875\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.4648 - categorical_accuracy: 0.8125 - val_loss: 0.6305 - val_categorical_accuracy: 0.8125\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.4097 - categorical_accuracy: 0.8633 - val_loss: 0.2572 - val_categorical_accuracy: 0.9531\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2086 - categorical_accuracy: 0.9102 - val_loss: 0.3716 - val_categorical_accuracy: 0.8438\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2303 - categorical_accuracy: 0.9023 - val_loss: 0.4512 - val_categorical_accuracy: 0.8281\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2431 - categorical_accuracy: 0.8945 - val_loss: 0.5098 - val_categorical_accuracy: 0.7969\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3910 - categorical_accuracy: 0.8320 - val_loss: 0.5836 - val_categorical_accuracy: 0.7500\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2594 - categorical_accuracy: 0.8906 - val_loss: 0.3470 - val_categorical_accuracy: 0.9062\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.1459 - categorical_accuracy: 0.9570 - val_loss: 0.2273 - val_categorical_accuracy: 0.9375\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0885 - categorical_accuracy: 0.9883 - val_loss: 0.2289 - val_categorical_accuracy: 0.9531\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0559 - categorical_accuracy: 1.0000 - val_loss: 0.1664 - val_categorical_accuracy: 0.9844\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0369 - categorical_accuracy: 1.0000 - val_loss: 0.2856 - val_categorical_accuracy: 0.9219\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0281 - categorical_accuracy: 1.0000 - val_loss: 0.2497 - val_categorical_accuracy: 0.9531\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0206 - categorical_accuracy: 1.0000 - val_loss: 0.2672 - val_categorical_accuracy: 0.9531\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0137 - categorical_accuracy: 1.0000 - val_loss: 0.2461 - val_categorical_accuracy: 0.9688\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0105 - categorical_accuracy: 1.0000 - val_loss: 0.2430 - val_categorical_accuracy: 0.9688\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0093 - categorical_accuracy: 1.0000 - val_loss: 0.2582 - val_categorical_accuracy: 0.9531\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0072 - categorical_accuracy: 1.0000 - val_loss: 0.2719 - val_categorical_accuracy: 0.9688\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0064 - categorical_accuracy: 1.0000 - val_loss: 0.2639 - val_categorical_accuracy: 0.9531\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0052 - categorical_accuracy: 1.0000 - val_loss: 0.2657 - val_categorical_accuracy: 0.9688\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.0048 - categorical_accuracy: 1.0000 - val_loss: 0.2884 - val_categorical_accuracy: 0.9531\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.0043 - categorical_accuracy: 1.0000 - val_loss: 0.2805 - val_categorical_accuracy: 0.9531\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0038 - categorical_accuracy: 1.0000 - val_loss: 0.2957 - val_categorical_accuracy: 0.9531\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.0035 - categorical_accuracy: 1.0000 - val_loss: 0.3075 - val_categorical_accuracy: 0.9531\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.0032 - categorical_accuracy: 1.0000 - val_loss: 0.3056 - val_categorical_accuracy: 0.9531\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0031 - categorical_accuracy: 1.0000 - val_loss: 0.3162 - val_categorical_accuracy: 0.9531\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0028 - categorical_accuracy: 1.0000 - val_loss: 0.3328 - val_categorical_accuracy: 0.9531\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.0026 - categorical_accuracy: 1.0000 - val_loss: 0.2970 - val_categorical_accuracy: 0.9531\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.0026 - categorical_accuracy: 1.0000 - val_loss: 0.3185 - val_categorical_accuracy: 0.9531\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 0.3327 - val_categorical_accuracy: 0.9531\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0021 - categorical_accuracy: 1.0000 - val_loss: 0.3205 - val_categorical_accuracy: 0.9531\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 0.3408 - val_categorical_accuracy: 0.9531\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.3383 - val_categorical_accuracy: 0.9531\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.3447 - val_categorical_accuracy: 0.9531\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 0.3462 - val_categorical_accuracy: 0.9531\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0018 - categorical_accuracy: 1.0000 - val_loss: 0.3303 - val_categorical_accuracy: 0.9531\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.3722 - val_categorical_accuracy: 0.9531\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 0.3346 - val_categorical_accuracy: 0.9531\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 0.3612 - val_categorical_accuracy: 0.9531\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 0.3348 - val_categorical_accuracy: 0.9531\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 0.3557 - val_categorical_accuracy: 0.9531\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 0.3445 - val_categorical_accuracy: 0.9531\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 0.3473 - val_categorical_accuracy: 0.9531\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.0010 - categorical_accuracy: 1.0000 - val_loss: 0.3525 - val_categorical_accuracy: 0.9531\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 9.9315e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3515 - val_categorical_accuracy: 0.9531\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 9.5318e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3582 - val_categorical_accuracy: 0.9531\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 9.1380e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3536 - val_categorical_accuracy: 0.9531\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 8.8064e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3639 - val_categorical_accuracy: 0.9531\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 8.6175e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3627 - val_categorical_accuracy: 0.9531\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 7.9093e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3513 - val_categorical_accuracy: 0.9531\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 7.7747e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3631 - val_categorical_accuracy: 0.9531\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 7.5235e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3585 - val_categorical_accuracy: 0.9531\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 7.1611e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3615 - val_categorical_accuracy: 0.9531\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 6.7622e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3612 - val_categorical_accuracy: 0.9531\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 6.6710e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3611 - val_categorical_accuracy: 0.9531\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 6.3430e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3596 - val_categorical_accuracy: 0.9531\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 6.0532e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3740 - val_categorical_accuracy: 0.9531\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 5.9907e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3664 - val_categorical_accuracy: 0.9531\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 5.8127e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3625 - val_categorical_accuracy: 0.9531\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 6.0535e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3807 - val_categorical_accuracy: 0.9531\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 6.1596e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3529 - val_categorical_accuracy: 0.9531\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 5.1211e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3684 - val_categorical_accuracy: 0.9531\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 5.7717e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3827 - val_categorical_accuracy: 0.9531\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 4.5931e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3603 - val_categorical_accuracy: 0.9531\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 4.9500e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3740 - val_categorical_accuracy: 0.9531\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 4.4109e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3799 - val_categorical_accuracy: 0.9531\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 4.2725e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3754 - val_categorical_accuracy: 0.9531\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 4.1997e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3754 - val_categorical_accuracy: 0.9531\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 4.2134e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3838 - val_categorical_accuracy: 0.9531\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 4.0817e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3736 - val_categorical_accuracy: 0.9531\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 3.8405e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3862 - val_categorical_accuracy: 0.9531\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 4.3086e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3956 - val_categorical_accuracy: 0.9531\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 3.5465e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3756 - val_categorical_accuracy: 0.9531\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 3.7127e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3893 - val_categorical_accuracy: 0.9531\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 3.4029e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3930 - val_categorical_accuracy: 0.9531\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 3.2792e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3914 - val_categorical_accuracy: 0.9531\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 3.4258e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3939 - val_categorical_accuracy: 0.9531\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 3.3653e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3999 - val_categorical_accuracy: 0.9531\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 3.0656e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3808 - val_categorical_accuracy: 0.9531\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 2.9962e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3882 - val_categorical_accuracy: 0.9531\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 3.0044e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3907 - val_categorical_accuracy: 0.9531\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 2.7457e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3974 - val_categorical_accuracy: 0.9531\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.6617e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3938 - val_categorical_accuracy: 0.9531\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 2.8254e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3920 - val_categorical_accuracy: 0.9531\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 2.6744e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4058 - val_categorical_accuracy: 0.9531\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 2.5860e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3970 - val_categorical_accuracy: 0.9531\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 2.4091e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3884 - val_categorical_accuracy: 0.9531\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 2.4290e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3934 - val_categorical_accuracy: 0.9531\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 2.6549e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4082 - val_categorical_accuracy: 0.9531\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 2.8935e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3826 - val_categorical_accuracy: 0.9531\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 2.2736e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4072 - val_categorical_accuracy: 0.9531\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 2.3572e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3941 - val_categorical_accuracy: 0.9531\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 2.0011e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4020 - val_categorical_accuracy: 0.9531\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 1.9127e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3893 - val_categorical_accuracy: 0.9531\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 1.7821e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3890 - val_categorical_accuracy: 0.9531\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.7243e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3859 - val_categorical_accuracy: 0.9531\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 1.6525e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3948 - val_categorical_accuracy: 0.9531\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.6170e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3950 - val_categorical_accuracy: 0.9531\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 1.5679e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3990 - val_categorical_accuracy: 0.9531\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 1.4938e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3998 - val_categorical_accuracy: 0.9531\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 1.5743e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4015 - val_categorical_accuracy: 0.9531\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 1.4189e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4071 - val_categorical_accuracy: 0.9531\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 1.4042e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4071 - val_categorical_accuracy: 0.9531\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 1.3714e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4058 - val_categorical_accuracy: 0.9531\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 1.3097e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4042 - val_categorical_accuracy: 0.9531\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 1.2497e-04 - categorical_accuracy: 1.0000 - val_loss: 0.3965 - val_categorical_accuracy: 0.9531\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 1.2917e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4031 - val_categorical_accuracy: 0.9531\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 1.2871e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4105 - val_categorical_accuracy: 0.9531\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 1.2853e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4169 - val_categorical_accuracy: 0.9531\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 1.1754e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4163 - val_categorical_accuracy: 0.9531\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 1.0884e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4073 - val_categorical_accuracy: 0.9531\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 1.0609e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4082 - val_categorical_accuracy: 0.9531\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.1399e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4136 - val_categorical_accuracy: 0.9531\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 1.0582e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4208 - val_categorical_accuracy: 0.9531\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 9.8538e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4194 - val_categorical_accuracy: 0.9531\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 9.2513e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4154 - val_categorical_accuracy: 0.9531\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15)\n",
    "model_checkpoint = ModelCheckpoint('LSTM_KNN_DTW_BEST_10words_test3.h5', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=300, callbacks=[model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('action10_best_95.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('action10_best_95.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = load_model('LSTM_KNN_DTW_BEST_10words_test3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"LSTM_try_6_with_more_test_best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596906 (2.28 MB)\n",
      "Trainable params: 596906 (2.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score,precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model_5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drink'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drink'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9149567099567101\n",
      "Recall: 0.8807142857142857\n",
      "F1 Score: 0.8898852202971197\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "precision = precision_score(ytrue, yhat, average='macro')  # or 'binary' if you have binary classification\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(ytrue, yhat, average='macro')  # or 'binary' if you have binary classification\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(ytrue, yhat, average='macro')  # or 'binary' if you have binary classification\n",
    "\n",
    "#accuracy score\n",
    "accuracy = accuracy_score(ytrue, yhat)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(ytrue, yhat)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=actions, yticklabels=actions)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_counts = np.bincount(y_train)  # Assuming y_train contains the class labels\n",
    "plt.bar(range(len(class_counts)), class_counts, tick_label=actions)\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = load_model('action2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation_history = model_5.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
    "  \n",
    "  metric_value_1 = model_training_history.history[metric_name_1]\n",
    "  metric_value_2 = model_training_history.history[metric_name_2]\n",
    "  \n",
    "  epochs = range(len(metric_value_1))\n",
    "  \n",
    "  #plot the graph\n",
    "  plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "  plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "  \n",
    "  plt.title(str(plot_name))\n",
    "  \n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history, 'loss', 'val_loss', 'Total Loss vs Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history, 'categorical_accuracy', 'val_categorical_accuracy', 'Total Accuracy vs Validation Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add noise to keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_noise(X, mean=0, std_dev=0.001):\n",
    "    noise = np.random.normal(mean, std_dev, X.shape)\n",
    "    return X + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise to X_test\n",
    "X_test_noisy = add_noise(X_test, mean=1, std_dev=0)\n",
    "\n",
    "# Making predictions with the noisy X_test\n",
    "yhat_noisy_probs = model_5.predict(X_test_noisy)\n",
    "\n",
    "# If the model outputs probabilities, convert them to class labels\n",
    "# Assuming a multi-class classification problem\n",
    "yhat_noisy = np.argmax(yhat_noisy_probs, axis=1)\n",
    "\n",
    "# Ensure y_test is in the same format\n",
    "y_test_labels = np.argmax(y_test, axis=1) if y_test.ndim > 1 else y_test\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(y_test_labels, yhat_noisy, average='macro')\n",
    "recall = recall_score(y_test_labels, yhat_noisy, average='macro')\n",
    "# F1 Score\n",
    "f1 = f1_score(ytrue, yhat_noisy, average='macro')  # or 'binary' if you have binary classification\n",
    "\n",
    "#accuracy score\n",
    "accuracy = accuracy_score(ytrue, yhat_noisy)\n",
    "\n",
    "\n",
    "print(f'Precision with noisy data: {precision}')\n",
    "print(f'Recall with noisy data: {recall}')\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_noisy = model_5.predict(X_test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "precision = precision_score(ytrue, yhat_noisy, average='macro')  # or 'binary' if you have binary classification\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(ytrue, yhat_noisy, average='macro')  # or 'binary' if you have binary classification\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(ytrue, yhat_noisy, average='macro')  # or 'binary' if you have binary classification\n",
    "\n",
    "#accuracy score\n",
    "accuracy = accuracy_score(ytrue, yhat_noisy)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, yhat_noisy, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Select the confusion matrix for the first class (index 0)\n",
    "plt.figure(figsize=(10, 7))  # Set the figure size\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)  # 'fmt' is the string format for numeric value\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "# Optional: Adjust the labels if you have specific class names\n",
    "class_labels = [\"hello\",\"thanks\",\"iloveyou\",\"yes\",\"no\"]  # Adjust according to your data\n",
    "plt.xticks(np.arange(len(class_labels)) + 0.5, class_labels, rotation=90)\n",
    "plt.yticks(np.arange(len(class_labels)) + 0.5, class_labels, rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245, 117, 16), (117, 245, 16), (16, 117, 245), (245, 16, 117), (117, 16, 245), (50, 50, 50),(16, 117, 245), (245, 16, 117), (117, 16, 245), (50, 50, 50)]\n",
    "\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.imshow(prob_viz(res, actions, image, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "            \n",
    "            \n",
    "        #3. Viz logic\n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "                if res[np.argmax(res)] > threshold: \n",
    "                    \n",
    "                    if len(sentence) > 0: \n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            predictions.append(np.argmax(res))\n",
    "            current_action = actions[np.argmax(res)] if res[np.argmax(res)] > threshold else \"\"\n",
    "\n",
    "        # 3. Viz logic\n",
    "        if len(predictions) > 10 and np.unique(predictions[-10:])[0] == np.argmax(res): \n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                if len(sentence) > 0: \n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "        if len(sentence) > 5: \n",
    "            sentence = sentence[-5:]\n",
    "\n",
    "        # Viz probabilities\n",
    "        if len(sequence) == 30:\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "\n",
    "        # Create a white image for text display\n",
    "        text_image = np.ones((frame.shape[0], 400, 3), dtype=np.uint8) * 255\n",
    "        cv2.putText(text_image, current_action, (10, frame.shape[0] // 2), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "        # Concatenate the image and text image\n",
    "        combined_image = np.hstack((image, text_image))\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', combined_image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_high_accuracy = load_model('action.h5')\n",
    "model_low_accuracy = load_model('test2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACTION\",model_high_accuracy.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test\",model_low_accuracy.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming models were compiled before saving\n",
    "optimizer_high = model_high_accuracy.optimizer.get_config()\n",
    "optimizer_low = model_low_accuracy.optimizer.get_config()\n",
    "\n",
    "print(\"High Accuracy Model Optimizer:\", optimizer_high)\n",
    "print(\"Low Accuracy Model Optimizer:\", optimizer_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your test dataset\n",
    "\n",
    "# Evaluate the models\n",
    "score_high = model_high_accuracy.evaluate(X_test, y_test, verbose=0)\n",
    "score_low = model_low_accuracy.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"High Accuracy Model Test Loss:\", score_high[0])\n",
    "print(\"High Accuracy Model Test Accuracy:\", score_high[1])\n",
    "\n",
    "print(\"Low Accuracy Model Test Loss:\", score_low[0])\n",
    "print(\"Low Accuracy Model Test Accuracy:\", score_low[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Predict the outputs\n",
    "y_pred_high = np.argmax(model_high_accuracy.predict(X_test), axis=-1)\n",
    "y_pred_low = np.argmax(model_low_accuracy.predict(X_test), axis=-1)\n",
    "y_true = np.argmax(y_test, axis=-1)\n",
    "\n",
    "# Confusion Matrix for High Accuracy Model\n",
    "cm_high = confusion_matrix(y_true, y_pred_high)\n",
    "ConfusionMatrixDisplay(cm_high).plot()\n",
    "plt.title('High Accuracy Model')\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix for Low Accuracy Model\n",
    "cm_low = confusion_matrix(y_true, y_pred_low)\n",
    "ConfusionMatrixDisplay(cm_low).plot()\n",
    "plt.title('Low Accuracy Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the layers have the same names and order\n",
    "for layer_high, layer_low in zip(model_high_accuracy.layers, model_low_accuracy.layers):\n",
    "    if len(layer_high.get_weights()) > 0:  # If the layer has weights\n",
    "        weights_high = layer_high.get_weights()[0]\n",
    "        weights_low = layer_low.get_weights()[0]\n",
    "\n",
    "        plt.hist(weights_high.flatten(), bins=50, alpha=0.5, label='High Accuracy')\n",
    "        plt.hist(weights_low.flatten(), bins=50, alpha=0.5, label='Low Accuracy')\n",
    "        plt.title(f'Weight Distribution in Layer {layer_high.name}')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
